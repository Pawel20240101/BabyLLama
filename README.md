# BabyLLama

These are 3 tasks completed as part of a homework assignment:
1. Run inference of Qwen3-0.6B using Colab or MLX (for Mac users). (Google Codelabs)
2. Train a 10M parameter LLaMA model on 0.5Mâ€“1B tokens (Laptop with Nvidia + CUDA optimized for GTX 1650)
3. Supervised finetune of Qwen2.5-0.5B Base using QLoRA (Google Codelabs)
Attached are the .ipynb files and a link to the repository.

https://huggingface.co/pawelzm
